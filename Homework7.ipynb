{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я разобрался с алгоритмом,но даже со словарём,в котором около 1000 слов (и соответсвенно в матрице примерно 300к не 0 элементов) программа работает оооочень долго. При том,что для стабилизации нужно хотя бы пара тысяч итераций,а проход по 1000 элементам матрицы занимает чуть меньше секунды,то получается,что не 0 элементов должно быть ~1-2к.что очень мало,честно,не знаю как написать код алгоритма оптимально. Т.к. сеиминара не было,решил отправитьвам PR ,можете,пожалуйста,подсказать : как следует оптимизировать код алгоритма?м "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True, max_df=0.9, min_df=0.01,\n",
       "                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                      'afterwards', 'again', 'against', 'all',\n",
       "                                      'almost', 'alone', 'along', 'already',\n",
       "                                      'also', 'although', 'always', 'am',\n",
       "                                      'among', 'amongst', 'amoungst', 'amount',\n",
       "                                      'an', 'and', 'another', 'any', 'anyhow',\n",
       "                                      'anyone', 'anything', 'anyway',\n",
       "                                      'anywhere', ...}))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=ENGLISH_STOP_WORDS,\n",
    "                             analyzer='word', binary=True,max_df=0.9,min_df=0.01)\n",
    "vectorizer.fit(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11314, 1142)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1 = vectorizer.transform(newsgroups_train.data)\n",
    "print(type(X_train1))\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "313237\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "print(type(X_train))\n",
    "X_train.shape\n",
    "a=X_train1.nonzero()\n",
    "a=np.transpose(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну,содержательная часть :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15840 15596 15654 15676 15468 15492 15605 15651 15500 15689 15557 15895\n",
      " 15738 15843 15605 15650 15890 15598 15701 15589]\n"
     ]
    }
   ],
   "source": [
    "const=50\n",
    "Ntopics=20\n",
    "alpha=1/Ntopics\n",
    "beta=const/X_train.shape[1]\n",
    "z=np.zeros((X_train.shape[0],X_train.shape[1]),dtype = np.int8)\n",
    "Nkw=np.zeros((Ntopics,X_train.shape[1]),dtype = np.int32)\n",
    "Ndk=np.zeros((Ntopics,X_train.shape[0]),dtype = np.int16)\n",
    "Nk=np.zeros(Ntopics,dtype = np.int32)\n",
    "for i in a :\n",
    "    c=np.random.randint(Ntopics)\n",
    "    Nkw[c,i[1]]+=1\n",
    "    Nk[c]+=1\n",
    "    #print(Nk)\n",
    "    Ndk[c,i[0]]+=1\n",
    "    z[i[0],i[1]]=c\n",
    "print(Nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во не 0 эл-ов\n",
      "313237\n",
      "0\n",
      "время на 1 итерацию\n",
      "201.17567038536072\n",
      "[ 0  0  0  0  0  8  0  0  0  0  1  0  0 10  0  0  0  4  0  0]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def lda(X_train,Nkw1,Ndk1,Nk1,z1) :\n",
    "    Ndk=Ndk1\n",
    "    Nkw=Nkw1\n",
    "    Nk=Nk1\n",
    "    z=z1\n",
    "    P=np.zeros(Ntopics,dtype = np.double)\n",
    "    a=X_train.nonzero()\n",
    "    a=np.transpose(a)\n",
    "    print(\"кол-во не 0 эл-ов\")\n",
    "    print(len(a))\n",
    "    for j in range(1) :\n",
    "        print(j)\n",
    "        start_time = time.time()\n",
    "        for i in a:\n",
    "            #gg+=1\n",
    "            #if gg%1000==0 : \n",
    "                #print(gg)\n",
    "            top=z[i[0],i[1]]\n",
    "            i0=i[0]\n",
    "            i1=i[1]\n",
    "            Ndk[top,i0]-=1\n",
    "            Nk[top]-=1\n",
    "            Nkw[top,i1]-=1\n",
    "            for k in range(Ntopics) :\n",
    "                P[k]=(Ndk[k,i0]+alpha)*(Nkw[k,i1]+beta)/(Nk[k]+const)\n",
    "            s=np.sum(P)\n",
    "            c=np.random.rand()*s\n",
    "            P=np.cumsum(P)\n",
    "            for t in range(Ntopics) :\n",
    "                if P[t] > c : \n",
    "                    z[i0,i1]=t \n",
    "                    break\n",
    "            Ndk[t,i0]+=1\n",
    "            Nk[t]+=1\n",
    "            Nkw[t,i1]+=1\n",
    "        print(\"время на 1 итерацию\")\n",
    "        print(time.time() - start_time)\n",
    "    return z,Ndk,Nkw\n",
    "z1=np.zeros((X_train.shape[0],X_train.shape[1]),dtype = np.int8)\n",
    "Nkw1=np.zeros((Ntopics,X_train.shape[1]),dtype = np.int8)\n",
    "Ndk1=np.zeros((Ntopics,X_train.shape[0]),dtype = np.int8)\n",
    "Nk1=np.zeros(Ntopics,dtype = np.int32)\n",
    "X_trainn=X_train[:100,:]\n",
    "z1,Ndk1,Nkw1=lda(X_train,Nkw,Ndk,Nk,z)\n",
    "print(Ndk1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
